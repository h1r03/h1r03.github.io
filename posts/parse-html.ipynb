{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "This post aims to introduce how to parse the HTML data fetched by `BeautifulSoup`\n",
    "\n",
    "\n",
    "**Reference**\n",
    "* [Using BeautifulSoup to parse HTML and extract press briefings URLs](http://www.compjour.org/warmups/govt-text-releases/intro-to-bs4-lxml-parsing-wh-press-briefings/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T06:26:22.754042Z",
     "start_time": "2019-05-24T06:26:22.709285Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple HTML from string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T06:53:50.720451Z",
     "start_time": "2019-05-24T06:53:50.715261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<h1>This is Title<h1>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_simple = '<h1>This is Title<h1>'\n",
    "html_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T06:53:50.920183Z",
     "start_time": "2019-05-24T06:53:50.915663Z"
    }
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T06:53:51.144228Z",
     "start_time": "2019-05-24T06:53:51.139311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is Title'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TEASER_END -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T06:52:51.239772Z",
     "start_time": "2019-05-24T06:52:51.232762Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASCII_SPACES',\n",
       " 'DEFAULT_BUILDER_FEATURES',\n",
       " 'HTML_FORMATTERS',\n",
       " 'NO_PARSER_SPECIFIED_WARNING',\n",
       " 'ROOT_TAG_NAME',\n",
       " 'XML_FORMATTERS',\n",
       " 'append',\n",
       " 'attrs',\n",
       " 'builder',\n",
       " 'can_be_empty_element',\n",
       " 'childGenerator',\n",
       " 'children',\n",
       " 'clear',\n",
       " 'contains_replacement_characters',\n",
       " 'contents',\n",
       " 'currentTag',\n",
       " 'current_data',\n",
       " 'declared_html_encoding',\n",
       " 'decode',\n",
       " 'decode_contents',\n",
       " 'decompose',\n",
       " 'descendants',\n",
       " 'encode',\n",
       " 'encode_contents',\n",
       " 'endData',\n",
       " 'extend',\n",
       " 'extract',\n",
       " 'fetchNextSiblings',\n",
       " 'fetchParents',\n",
       " 'fetchPrevious',\n",
       " 'fetchPreviousSiblings',\n",
       " 'find',\n",
       " 'findAll',\n",
       " 'findAllNext',\n",
       " 'findAllPrevious',\n",
       " 'findChild',\n",
       " 'findChildren',\n",
       " 'findNext',\n",
       " 'findNextSibling',\n",
       " 'findNextSiblings',\n",
       " 'findParent',\n",
       " 'findParents',\n",
       " 'findPrevious',\n",
       " 'findPreviousSibling',\n",
       " 'findPreviousSiblings',\n",
       " 'find_all',\n",
       " 'find_all_next',\n",
       " 'find_all_previous',\n",
       " 'find_next',\n",
       " 'find_next_sibling',\n",
       " 'find_next_siblings',\n",
       " 'find_parent',\n",
       " 'find_parents',\n",
       " 'find_previous',\n",
       " 'find_previous_sibling',\n",
       " 'find_previous_siblings',\n",
       " 'format_string',\n",
       " 'get',\n",
       " 'getText',\n",
       " 'get_attribute_list',\n",
       " 'get_text',\n",
       " 'handle_data',\n",
       " 'handle_endtag',\n",
       " 'handle_starttag',\n",
       " 'has_attr',\n",
       " 'has_key',\n",
       " 'hidden',\n",
       " 'index',\n",
       " 'insert',\n",
       " 'insert_after',\n",
       " 'insert_before',\n",
       " 'isSelfClosing',\n",
       " 'is_empty_element',\n",
       " 'is_xml',\n",
       " 'known_xml',\n",
       " 'markup',\n",
       " 'name',\n",
       " 'namespace',\n",
       " 'new_string',\n",
       " 'new_tag',\n",
       " 'next',\n",
       " 'nextGenerator',\n",
       " 'nextSibling',\n",
       " 'nextSiblingGenerator',\n",
       " 'next_element',\n",
       " 'next_elements',\n",
       " 'next_sibling',\n",
       " 'next_siblings',\n",
       " 'object_was_parsed',\n",
       " 'original_encoding',\n",
       " 'parent',\n",
       " 'parentGenerator',\n",
       " 'parents',\n",
       " 'parse_only',\n",
       " 'parserClass',\n",
       " 'parser_class',\n",
       " 'popTag',\n",
       " 'prefix',\n",
       " 'preserve_whitespace_tag_stack',\n",
       " 'preserve_whitespace_tags',\n",
       " 'prettify',\n",
       " 'previous',\n",
       " 'previousGenerator',\n",
       " 'previousSibling',\n",
       " 'previousSiblingGenerator',\n",
       " 'previous_element',\n",
       " 'previous_elements',\n",
       " 'previous_sibling',\n",
       " 'previous_siblings',\n",
       " 'pushTag',\n",
       " 'recursiveChildGenerator',\n",
       " 'renderContents',\n",
       " 'replaceWith',\n",
       " 'replaceWithChildren',\n",
       " 'replace_with',\n",
       " 'replace_with_children',\n",
       " 'reset',\n",
       " 'select',\n",
       " 'select_one',\n",
       " 'setup',\n",
       " 'string',\n",
       " 'strings',\n",
       " 'stripped_strings',\n",
       " 'tagStack',\n",
       " 'text',\n",
       " 'unwrap',\n",
       " 'wrap']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c in dir(soup) if not c.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T06:25:12.640054Z",
     "start_time": "2019-05-24T06:25:12.633999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>This is Title<h1></h1></h1>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T06:25:18.697122Z",
     "start_time": "2019-05-24T06:25:18.694035Z"
    }
   },
   "outputs": [],
   "source": [
    "soup.h2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing HTML webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T06:26:50.756846Z",
     "start_time": "2019-05-24T06:26:50.551688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\nHome | Step-by-step Data Science\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  window.dataLayer = window.dataLayer || [];\\n  function gtag(){dataLayer.push(arguments);}\\n  gtag(\\'js\\', new Date());\\n\\n  gtag(\\'config\\', \\'UA-134273341-1\\');\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main content\\n\\n\\n\\n\\n\\nToggle navigation\\n\\n\\n\\n\\n\\nStep-by-step Data Science\\n\\n\\n\\n\\n\\n\\nCoding Problems\\n\\n\\nMachine Learning\\n\\n\\nAll \\n\\n\\nAll Post\\n\\n\\nCategories and Tags\\n\\n\\nHistory\\n\\n\\n\\n\\nRSS\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Step by Step \\n\\n\\n\\n\\n\\n\\n\\n\\nAbout me\\n\\nI am Hiro, who is passionate about data science and deep learning. I have a few years of industry and research experinence in machine learning. By explaining things to learn, I would like to accerelate my learning process, but step by step.  \\n\\t\\t\\n\\n\\n\\n\\nExpected Readers\\n\\nI mainly write about it for myself but hope it would be benefitial for those who learn machine learning and coding. I am very happy to work and think together if anyone has a question. Feel free to leave a comment or use chat located at the right bottom.  \\n\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCoding Problem\\n\"Compare yourself with who you were yesterday\"\\n\\nEvery Sturday I join LeetCode Weekly Contest and improve coding skill by solving coding problems. I know there are a lot of better coders in the world but I compare myself who I was yesterday to move forward.\\n\\n\\n\\n\\nDynamic Programming\\n\\n\\nBinary Tree\\n\\nRecursive\\n      \\t\\nLinked List\\n      \\t\\nHeap\\n      \\n\\n\\n\\n\\n\\n\\nMachine Learning\\n\"The best way to learn is to explain\"\\n\\nEven if we can use them, we do not fully understand the things. I explain the things I used for my daily job as well as the ones that I would like to learn. \\n\\n\\nPreprocessing\\n\\n\\nVisualization\\n\\n\\nText\\n\\nAudio\\n      \\t\\nImages\\n    \\t\\nDeep Learning\\n\\n      \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Contents Â© 2019         h1ros - Powered by         Nikola\\n\\n\\n\\n\\n  ((window.gitter = {}).chat = {}).options = {\\n    room: \\'h1ros-github-io/ama\\'\\n  };\\n\\n    moment.locale(\"en\");\\n    fancydates(1, \"YYYY-MM-DD\");\\n    \\n    baguetteBox.run(\\'div#content\\', {\\n        ignoreClass: \\'islink\\',\\n        captions: function(element) {\\n            return element.getElementsByTagName(\\'img\\')[0].alt;\\n    }});\\n    window.twttr = (function(d, s, id) {\\n  var js, fjs = d.getElementsByTagName(s)[0],\\n    t = window.twttr || {};\\n  if (d.getElementById(id)) return t;\\n  js = d.createElement(s);\\n  js.id = id;\\n  js.src = \"https://platform.twitter.com/widgets.js\";\\n  fjs.parentNode.insertBefore(js, fjs);\\n  t._e = [];\\n  t.ready = function(f) {\\n    t._e.push(f);\\n  };\\n  return t;\\n}(document, \"script\", \"twitter-wjs\"));\\n\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_html = 'https://h1ros.github.io/'\n",
    "response = requests.get(target_html)\n",
    "soup = BeautifulSoup(response.text)\n",
    "soup.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T06:29:05.905226Z",
     "start_time": "2019-05-24T06:29:05.901946Z"
    }
   },
   "source": [
    "## Collect all href in tag <a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-24T06:28:40.657437Z",
     "start_time": "2019-05-24T06:28:40.651012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#content',\n",
       " '.',\n",
       " 'categories/coding',\n",
       " 'categories/machine-learning',\n",
       " '#',\n",
       " 'posts/',\n",
       " 'categories/',\n",
       " 'archive.html',\n",
       " 'rss.xml',\n",
       " '.',\n",
       " '.',\n",
       " 'categories/coding/',\n",
       " '.',\n",
       " 'categories/coding/',\n",
       " 'categories/dynamic-programming',\n",
       " 'categories/binary-tree',\n",
       " 'categories/machine-learning/',\n",
       " '.',\n",
       " 'categories/machine-learning/',\n",
       " 'categories/peprocessing',\n",
       " 'categories/visualization',\n",
       " 'categories/text',\n",
       " 'mailto:data.h1ros@gmail.com',\n",
       " 'https://getnikola.com']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_urls = []\n",
    "for a in soup.find_all('a'):\n",
    "    all_urls.append(a.attrs['href'])\n",
    "    \n",
    "all_urls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py367)",
   "language": "python",
   "name": "py367"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "nikola": {
   "category": "Machine Learning",
   "date": "2019-05-23 23:18:35 UTC-07:00",
   "description": "",
   "link": "",
   "slug": "parse-html",
   "tags": "Text Processing, beautifulsoup, preprocessing",
   "title": "Parse HTML",
   "type": "text"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
