{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal \n",
    "This post aims to introduce how to train the image classifier for MNIST dataset using PyTorch\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/8764683/59977812-c7f6e380-9610-11e9-8a22-25f215a9a2e8.png)\n",
    "\n",
    "**Reference**\n",
    "* [PyTorch Documentation - TORCHVISION.DATASETS](https://pytorch.org/docs/stable/torchvision/datasets.html#mnist)\n",
    "* [PyTorch Tutorial - TRAINING A CLASSIFIER](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)\n",
    "* [Kaggle kernel - CNN with Pytorch for MNIST ](https://www.kaggle.com/sdelecourt/cnn-with-pytorch-for-mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T00:59:48.742181Z",
     "start_time": "2019-06-23T00:59:48.733112Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Dataset\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# PyTorch\n",
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T14:19:52.151023Z",
     "start_time": "2019-06-23T14:19:52.145303Z"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5 # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST dataset\n",
    "\n",
    "When downloading the image dataset, we also need to define `transform` function that apply pixel normalization from [0, 1] to [-1, +1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T14:28:16.491574Z",
     "start_time": "2019-06-23T14:28:16.437067Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "9920512it [00:28, 1582029.76it/s]                             \u001b[A\n",
      "\n",
      "1654784it [00:23, 573182.07it/s]                             \u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, ), (0.5, ))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='~/data', \n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='~/data', \n",
    "                                        train=False, \n",
    "                                        download=True, \n",
    "                                        transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:02:54.543085Z",
     "start_time": "2019-06-23T13:02:54.532174Z"
    }
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=100,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:02:56.213077Z",
     "start_time": "2019-06-23T13:02:56.209173Z"
    }
   },
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                         batch_size=100,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T00:59:22.967561Z",
     "start_time": "2019-06-23T00:59:22.957557Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)  # 28x28x32 -> 26x26x32\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)  # 26x26x64 -> 24x24x64\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 24x24x64 -> 12x12x64\n",
    "        self.dropout1 = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(12 * 12 * 64, 128)\n",
    "        self.dropout2 = nn.Dropout2d()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = x.view(-1, 12 * 12 * 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T01:00:07.384686Z",
     "start_time": "2019-06-23T01:00:07.357383Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T13:24:48.692721Z",
     "start_time": "2019-06-23T13:05:12.228144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 100] loss: 1.5\n",
      "[1, 200] loss: 0.82\n",
      "[1, 300] loss: 0.63\n",
      "[1, 400] loss: 0.55\n",
      "[1, 500] loss: 0.5\n",
      "[1, 600] loss: 0.46\n",
      "[2, 100] loss: 0.42\n",
      "[2, 200] loss: 0.4\n",
      "[2, 300] loss: 0.38\n",
      "[2, 400] loss: 0.38\n",
      "[2, 500] loss: 0.34\n",
      "[2, 600] loss: 0.34\n",
      "[3, 100] loss: 0.31\n",
      "[3, 200] loss: 0.31\n",
      "[3, 300] loss: 0.29\n",
      "[3, 400] loss: 0.28\n",
      "[3, 500] loss: 0.28\n",
      "[3, 600] loss: 0.26\n",
      "[4, 100] loss: 0.24\n",
      "[4, 200] loss: 0.24\n",
      "[4, 300] loss: 0.24\n",
      "[4, 400] loss: 0.23\n",
      "[4, 500] loss: 0.23\n",
      "[4, 600] loss: 0.22\n",
      "[5, 100] loss: 0.2\n",
      "[5, 200] loss: 0.21\n",
      "[5, 300] loss: 0.2\n",
      "[5, 400] loss: 0.19\n",
      "[5, 500] loss: 0.19\n",
      "[5, 600] loss: 0.19\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f'[{epoch + 1}, {i+1}] loss: {running_loss / 100:.2}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T14:21:48.943896Z",
     "start_time": "2019-06-23T14:21:48.708070Z"
    }
   },
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T14:25:08.438461Z",
     "start_time": "2019-06-23T14:25:08.367134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ground Truth</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted label</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0  1  2  3  4  5  6  7  8  9\n",
       "Ground Truth     7  2  1  0  4  1  4  9  5  9\n",
       "Predicted label  7  2  1  0  4  1  4  9  6  9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_test = 10\n",
    "df_result = pd.DataFrame({\n",
    "    'Ground Truth': labels[:n_test],\n",
    "    'Predicted label': predicted[:n_test]})\n",
    "display(df_result.T)\n",
    "imshow(torchvision.utils.make_grid(images[:n_test, :, :, :], nrow=n_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py367)",
   "language": "python",
   "name": "py367"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "nikola": {
   "category": "Machine Learning",
   "date": "2019-06-22 17:50:57 UTC-07:00",
   "description": "introduce how to train the image classifier for MNIST using pytorch",
   "link": "",
   "slug": "train-the-image-classifier-using-pytorch",
   "tags": "PyTorch, Deep Learning, MNIST, Image",
   "title": "Train the image classifier using PyTorch",
   "type": "text"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
